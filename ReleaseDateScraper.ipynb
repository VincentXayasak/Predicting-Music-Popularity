{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "X53rL2Uqbu3J"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob8uyQE5b1Lm",
        "outputId": "ff4265ad-0247-42c3-c932-4dd6e18cb467"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"music_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc0uGHAkb5x0",
        "outputId": "27f8bb13-07ab-4abb-c686-fdac1efbf34f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 114000 entries, 0 to 113999\n",
            "Data columns (total 21 columns):\n",
            " #   Column            Non-Null Count   Dtype  \n",
            "---  ------            --------------   -----  \n",
            " 0   Unnamed: 0        114000 non-null  int64  \n",
            " 1   track_id          114000 non-null  object \n",
            " 2   artists           113999 non-null  object \n",
            " 3   album_name        113999 non-null  object \n",
            " 4   track_name        113999 non-null  object \n",
            " 5   popularity        114000 non-null  int64  \n",
            " 6   duration_ms       114000 non-null  int64  \n",
            " 7   explicit          114000 non-null  bool   \n",
            " 8   danceability      114000 non-null  float64\n",
            " 9   energy            114000 non-null  float64\n",
            " 10  key               114000 non-null  int64  \n",
            " 11  loudness          114000 non-null  float64\n",
            " 12  mode              114000 non-null  int64  \n",
            " 13  speechiness       114000 non-null  float64\n",
            " 14  acousticness      114000 non-null  float64\n",
            " 15  instrumentalness  114000 non-null  float64\n",
            " 16  liveness          114000 non-null  float64\n",
            " 17  valence           114000 non-null  float64\n",
            " 18  tempo             114000 non-null  float64\n",
            " 19  time_signature    114000 non-null  int64  \n",
            " 20  track_genre       114000 non-null  object \n",
            "dtypes: bool(1), float64(9), int64(6), object(5)\n",
            "memory usage: 17.5+ MB\n"
          ]
        }
      ],
      "source": [
        "# Meta Data\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h28P9YvacE3u",
        "outputId": "5da1e0be-09fb-4463-a305-d3a7edb9bfb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Unnamed: 0                track_id                 artists  \\\n",
            "0           0  5SuOikwiRyPMVoIQDJUgSV             Gen Hoshino   \n",
            "1           1  4qPNDBW1i3p13qLCt0Ki3A            Ben Woodward   \n",
            "2           2  1iJBSr7s7jYXzM8EGcbK5b  Ingrid Michaelson;ZAYN   \n",
            "3           3  6lfxq3CG4xtTiEg7opyCyx            Kina Grannis   \n",
            "4           4  5vjLSffimiIP26QG5WcN2K        Chord Overstreet   \n",
            "\n",
            "                                          album_name  \\\n",
            "0                                             Comedy   \n",
            "1                                   Ghost (Acoustic)   \n",
            "2                                     To Begin Again   \n",
            "3  Crazy Rich Asians (Original Motion Picture Sou...   \n",
            "4                                            Hold On   \n",
            "\n",
            "                   track_name  popularity  duration_ms  explicit  \\\n",
            "0                      Comedy          73       230666     False   \n",
            "1            Ghost - Acoustic          55       149610     False   \n",
            "2              To Begin Again          57       210826     False   \n",
            "3  Can't Help Falling In Love          71       201933     False   \n",
            "4                     Hold On          82       198853     False   \n",
            "\n",
            "   danceability  energy  ...  loudness  mode  speechiness  acousticness  \\\n",
            "0         0.676  0.4610  ...    -6.746     0       0.1430        0.0322   \n",
            "1         0.420  0.1660  ...   -17.235     1       0.0763        0.9240   \n",
            "2         0.438  0.3590  ...    -9.734     1       0.0557        0.2100   \n",
            "3         0.266  0.0596  ...   -18.515     1       0.0363        0.9050   \n",
            "4         0.618  0.4430  ...    -9.681     1       0.0526        0.4690   \n",
            "\n",
            "   instrumentalness  liveness  valence    tempo  time_signature  track_genre  \n",
            "0          0.000001    0.3580    0.715   87.917               4     acoustic  \n",
            "1          0.000006    0.1010    0.267   77.489               4     acoustic  \n",
            "2          0.000000    0.1170    0.120   76.332               4     acoustic  \n",
            "3          0.000071    0.1320    0.143  181.740               3     acoustic  \n",
            "4          0.000000    0.0829    0.167  119.949               4     acoustic  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        }
      ],
      "source": [
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FrJ7_EnZhxKo"
      },
      "outputs": [],
      "source": [
        "df = df[df['popularity'] != 0]  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBXQaBrMs2rD",
        "outputId": "eb38997f-38d3-42ea-86d4-cb567df6e72c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 100 new track IDs to process...\n",
            "1/100. 5SuOikwiRyPMVoIQDJUgSV → 2022-04-08\n",
            "2/100. 4qPNDBW1i3p13qLCt0Ki3A → 2021-04-30\n",
            "3/100. 1iJBSr7s7jYXzM8EGcbK5b → 2021-03-17\n",
            "4/100. 6lfxq3CG4xtTiEg7opyCyx → 2018-08-10\n",
            "5/100. 5vjLSffimiIP26QG5WcN2K → 2017-02-03\n",
            "6/100. 01MVOl9KtVTNfFiBU9I7dc → 2018-04-20\n",
            "7/100. 6Vc5wAMmXdKIAM7WUoEb7N → 2014-01-20\n",
            "8/100. 1EzrEOXmMH3G43AXT1y7pA → 2008-05-12\n",
            "9/100. 0IktbUcnAGrvD03AWnz3Q8 → 2008-05-12\n",
            "10/100. 7k9GuJYLp2AzqokyEdwEw2 → 2015-04-21\n",
            "11/100. 4mzP5mHkRvGxdhdGdAH7EJ → 2021-10-15\n",
            "12/100. 5ivF4eQBqJiVL5IAE9jRyl → 2012-04-13\n",
            "13/100. 4ptDJbJl35d7gQfeNteBwp → 2018-06-15\n",
            "14/100. 0X9MxHR1rTkEHDjp95F2OO → 2018-12-14\n",
            "15/100. 4LbWtBkN82ZRhz9jqzgrb3 → 2017-05-19\n",
            "16/100. 1KHdq8NK9QxnGjdXb55NiG → 2009-09-24\n",
            "17/100. 6xKeQgzfjixSUld14qUezm → 2020-07-09\n",
            "18/100. 4Yo0igmcoNyat1secaH0OD → 2020-12-31\n",
            "19/100. 2qLMf6TuEC3ruGJg4SMMN6 → 2008-05-01\n",
            "20/100. 6CgNoAbFJ4Q4Id4EjtbXlC → 2017-12-19\n",
            "21/100. 3S0OXQeoh0w6AY8WQVckRW → 2008-05-01\n",
            "22/100. 210JCw2LbYD4YIs8GiZ9iP → 2015-04-28\n",
            "23/100. 5TvE3pk05pyFIGdSY9j4DJ → 2014-01-13\n",
            "24/100. 6D33wCKzWtNEgOovgeVJ7r → 2022-10-07\n",
            "25/100. 72xTsTouZ5nBmASX8k1XCW → 2019-11-22\n",
            "26/100. 3ILmwMefYZoQh5Cf5jeuUQ → 2010-10-06\n",
            "27/100. 2DHDuADAHoUW6n0z80RLQF → 2013-08-20\n",
            "28/100. 5JDcQAztvZTIkrWoZihgvC → 2008-07-14\n",
            "29/100. 2sYFi9xVSZ56WHKSY2fN1K → 2017-12-08\n",
            "30/100. 6xJOhSm4SvZwzy3uhWz26O → 2013-08-20\n",
            "31/100. 7lLKxcNeJtDTWVRKHovLEC → 2015-03-19\n",
            "32/100. 4oa14QBfWRDfJy2agySy0L → 2007-07-03\n",
            "33/100. 2gRKq9rIC5i1zuxp06zJWH → 2021-06-04\n",
            "34/100. 08MFgEQeVLF37EyZ7jcwLc → 2021-12-06\n",
            "35/100. 6nXIYClvJAfi6ujLiKqEq8 → 2012-02-28\n",
            "36/100. 7x4b0UccXSKBWxWmjcrG2T → 2015-11-13\n",
            "37/100. 6owKuyHxUqidcAA6fPKSyy → 2015-04-28\n",
            "38/100. 0wbmIfvndFV9VDvuUY1pYN → 2019-04-19\n",
            "39/100. 3e5yu9MkIvQx17mm7LF6KY → 2016-09-09\n",
            "40/100. 6VwAh8Z1d5YKoSWoEaV4db → 2015-01-01\n",
            "41/100. 2D4BSm5Z8Hq5zYbSgJwEOh → 2015-11-06\n",
            "42/100. 7LwGBxB0h0CVmkOZxYKn0g → 2010-05-21\n",
            "43/100. 0ZwdH0m32I8odedwvspYTh → 2017-04-24\n",
            "44/100. 16dkWKIlBsfYTISCVuDs0w → 2011-04-07\n",
            "45/100. 3TwtrR1yNLY1PMPsrGQpOp → 2000-09-26\n",
            "46/100. 3Et4LKZLnXygPYfNdeB3D3 → 2017-08-25\n",
            "47/100. 2E9viCx0hJKNKNThd2MdGQ → 2019-03-08\n",
            "48/100. 0Zf1BPkkFAWGtVHeBwHHz4 → 2016-08-26\n",
            "49/100. 38jy6kRlPt8z1GUS9WXeNh → 2012-04-13\n",
            "50/100. 2SkJKMfjpYsNv0KWOxiegX → 2015-11-13\n",
            "51/100. 4qCbMMMuEB56kHd4zPE6GD → 2010-01-01\n",
            "52/100. 11TK5KLtLZUdKr1C549bAw → 2013-02-19\n",
            "53/100. 7BXW1QCg56yzEBV8pW8pah → 2018-08-10\n",
            "54/100. 3bHhUEOTIbezeZ856R0BX5 → 2007-09-18\n",
            "55/100. 4LGF2tDg3878bs0mQPByZ4 → 2007-09-18\n",
            "56/100. 6Uy6K3KdmUdAfelUp0SeXn → 2013-07-16\n",
            "57/100. 0qJGlogD7AyMLAJfQ42aI2 → 2013-09-17\n",
            "58/100. 0U32q8CZRRo7xCzyiaZw5f → 2013-05-29\n",
            "59/100. 4kQXMVjoZ9yMibLZq5Aqi5 → 2020-03-20\n",
            "60/100. 3us8sod4dLbM9FiMiPiEY8 → 2014-10-07\n",
            "61/100. 1PR5pyPiOEEQ02oJYq402x → 2015-04-28\n",
            "62/100. 068qo0w1Ki0cjnFYOUhAm2 → 2021-01-15\n",
            "63/100. 2RFt6ZWQbr9mPhsft9u9eX → 2020-01-17\n",
            "64/100. 59pUIlXjQupbiYwt40uUTi → 2016-10-05\n",
            "65/100. 0VhZ5JYfqPojSYeGWnk4dL → 2018-09-03\n",
            "66/100. 0ltIx8PLjtWoS9zn9PqsZW → 2021-10-14\n",
            "67/100. 7ACW42whcdOiUxiNVu7ltx → 2020-11-20\n",
            "68/100. 4qTHoIp62ngNDpUJwW3hZ7 → 2020-05-15\n",
            "69/100. 4VbDTk82rqWqVgoQC93CkC → 2018-10-12\n",
            "70/100. 1pG5nd6gmfbMwUfT5shDQe → 2018-12-21\n",
            "71/100. 2WZyfujzMweFLnozyUJBkW → 2005-01-01\n",
            "72/100. 6gijbGNDNNJgT60Aj7UCyc → 2016-01-15\n",
            "73/100. 5pq4v03P5PxMcnCagg4S3Z → 2017-12-19\n",
            "74/100. 08OjvLnGR3M0HUhcePeMNO → 2020-05-07\n",
            "75/100. 65VhbQdqvozUntjnlFkFbZ → 2018-05-11\n",
            "76/100. 05pKAafT85jeeNhZ6kq7HT → 2012-01-03\n",
            "77/100. 3PG6V5yuFfo4APiovOQoRv → 2022-04-08\n",
            "78/100. 5O9R57EozcpLKGQBzadPVy → 2021-01-24\n",
            "79/100. 6ta5yavnnEfCE4faU0jebM → 2006-01-01\n",
            "80/100. 7BRCa8MPiyuvr2VU3O9W0F → 2012-05-15\n",
            "81/100. 5ZhaKUsY68U0lgREFWfoxg → 2011-05-03\n",
            "82/100. 4zcMBfbQZvBSHQBGDd6gsN → 2020-04-06\n",
            "83/100. 7bhHLZxkRekrNPPkEdDTbn → 2017-02-07\n",
            "84/100. 5rwq6R0Uq0BngM3rdmCeNg → 2003-11-04\n",
            "85/100. 2lxBZVbkiCXC1soks2RXwV → 2018-06-22\n",
            "86/100. 38YgZVHPWOWsKrsCXz6JyP → 2007-01-01\n",
            "87/100. 6XrNrp7UtGgyZcHJ0ckL0w → 2019-04-05\n",
            "88/100. 72R0X0h8YaxYNpegeoOl0M → 2011-01-01\n",
            "89/100. 6R6ux6KaKrhAg2EIB2krdU → 2016-01-15\n",
            "90/100. 2D9w6sabdMCLSheW5aegwO → 2022-10-14\n",
            "91/100. 1Qo3taHLFSQpzLm5Sty7M4 → 2022-10-14\n",
            "92/100. 71M4QMn8nrok1KFVXwEEyU → 2022-10-14\n",
            "93/100. 4lxGVzcUaSF5HW5jtWnShV → 2007-09-18\n",
            "94/100. 2PIlBukQ6limukVR8Ubb5o → 2013-05-13\n",
            "95/100. 5p9XWUdvbUzmPCukOmwoU3 → 2005-01-01\n",
            "96/100. 1uSuY2qLCbx1QB7oPUVhFG → 2022-10-14\n",
            "97/100. 6twvFrIoIINH8UW8EB8OnU → 2022-10-14\n",
            "98/100. 2pelUnMKr07JjJpilj9Yew → 2022-10-14\n",
            "99/100. 7d0bJhpp0mCYyMXaMgWyMS → 2018-10-08\n",
            "100/100. 73CbJykoV6WapWGfTeRzTl → 2022-10-14\n",
            "\n",
            "Done with this batch! Results saved to: release_dates.txt\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "\n",
        "# Load filtered track IDs (assumes `df` is already defined and loaded)\n",
        "df_filtered = df.iloc[0:] \n",
        "all_ids = df_filtered['track_id'].dropna().unique()\n",
        "\n",
        "# Output file path\n",
        "output_path = 'spotify_release_dates_merged.txt'\n",
        "processed_ids = set()\n",
        "\n",
        "# Load already processed IDs\n",
        "try:\n",
        "    with open(output_path, 'r') as f:\n",
        "        for line in f:\n",
        "            tid = line.strip().split(' - ')[0]\n",
        "            processed_ids.add(tid)\n",
        "except FileNotFoundError:\n",
        "    pass  # If file doesn't exist, start fresh\n",
        "\n",
        "# Filter unprocessed track IDs and limit the batch\n",
        "to_process = [tid for tid in all_ids if tid not in processed_ids][:100]\n",
        "print(f\"Found {len(to_process)} new track IDs to process...\")\n",
        "\n",
        "# Scrape release dates and append to file\n",
        "with open(output_path, 'a') as f:\n",
        "    for i, track_id in enumerate(to_process):\n",
        "        try:\n",
        "            url = f'https://open.spotify.com/track/{track_id}'\n",
        "            headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "            res = requests.get(url, headers=headers, timeout=10)\n",
        "            soup = BeautifulSoup(res.text, 'html.parser')\n",
        "            meta = soup.find('meta', {'name': 'music:release_date'})\n",
        "\n",
        "            if meta and meta.get('content'):\n",
        "                release_date = meta['content']\n",
        "                f.write(f\"{track_id} - {release_date}\\n\")\n",
        "                print(f\"{i+1}/{len(to_process)}. {track_id} → {release_date}\")\n",
        "            else:\n",
        "                f.write(f\"{track_id} - NOT FOUND\\n\")\n",
        "                print(f\"{i+1}/{len(to_process)}. {track_id} → No release date found\") \n",
        "        except Exception as e:\n",
        "            f.write(f\"{track_id} - ERROR\\n\")\n",
        "            print(f\"{i+1}/{len(to_process)}. {track_id} → GENERAL ERROR: {e}\")\n",
        "\n",
        "        time.sleep(0.25)  # Be respectful to Spotify's servers\n",
        "\n",
        "print(f\"\\nDone with this batch! Results saved to: {output_path}\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNMXhE37lMTo",
        "outputId": "a41cf79d-5970-4680-f82a-f6cad4f0f861"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: 100 release dates collected so far.\n"
          ]
        }
      ],
      "source": [
        "# Path to your output file\n",
        "output_path = 'spotify_release_dates_merged.txt'\n",
        "\n",
        "# Count how many lines (observations) are in the file\n",
        "with open(output_path, 'r') as f:\n",
        "    num_lines = sum(1 for _ in f)\n",
        "\n",
        "print(f\"Progress: {num_lines} release dates collected so far.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
